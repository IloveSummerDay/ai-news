name: Daily AI News Crawl with LLM

on:
    # schedule:
    #   - cron: '0 0,4,8,12,16,20 * * *'  # Runs 6 times daily every 4 hours (00:00, 04:00, 08:00, 12:00, 16:00, 20:00 UTC)
    workflow_dispatch: # Manual trigger for testing
    push:
        branches: [main] # Also run on pushes to main for testing

jobs:
    crawl-and-build:
        runs-on: ubuntu-latest
        timeout-minutes: 45 # Allow time(minutes) for model downloads

        permissions:
            contents: write # Allow pushing changes
            pages: write # Allow GitHub Pages deployment
            id-token: write # Required for pages deployment

        steps:
            - name: Checkout repository
              uses: actions/checkout@v4
              with:
                  token: ${{ secrets.GITHUB_TOKEN }}

            - name: Setup Node.js
              uses: actions/setup-node@v4
              with:
                  node-version: '18'
                  cache: 'npm'

            - name: Install dependencies
              run: |
                  npm ci
                  echo "Dependencies installed"

            - name: Create directories
              run: |
                  mkdir -p data
                  mkdir -p site
                  mkdir -p .cache

            - name: Crawl RSS feeds
              run: |
                  echo "ü§ñ Starting RSS crawl..."
                  node scripts/crawl.js
                  echo "Crawl completed"

            - name: Optimize and validate
              run: |
                  # Validate JSON files
                  echo "üîç Validating data files..."
                  node -e "
                    const fs = require('fs');
                    try {
                      JSON.parse(fs.readFileSync('data/latest-raw.json'));
                      console.log('‚úÖ Data files valid');
                    } catch(e) {
                      console.error('‚ùå Invalid JSON:', e.message);
                      process.exit(1);
                    }
                  "

                  # Check if we have articles
                  ARTICLE_COUNT=$(node -e "console.log(JSON.parse(require('fs').readFileSync('data/latest-raw.json')).articles.length)")
                  echo "üìä Found $ARTICLE_COUNT articles"

                  if [ "$ARTICLE_COUNT" -lt 10 ]; then
                    echo "‚ö†Ô∏è Warning: Low article count ($ARTICLE_COUNT)"
                  fi

            - name: Report status
              run: |
                  echo "‚úÖ Workflow completed successfully!"
                  echo "üìä Statistics:"
                  node -e "
                    const data = JSON.parse(require('fs').readFileSync('data/latest-raw.json'));
                    console.log(\`Articles: \${data.articles.length}\`);
                  "

# Environment variables for the workflow
env:
    NODE_OPTIONS: '--max-old-space-size=4096' # Increase memory for AI models
    ORT_LOG_LEVEL: '3' # Suppress ONNX runtime warnings
    ONNX_DISABLE_WARNINGS: '1'
    ONNXRUNTIME_LOG_LEVEL: '3'
    CONFIDENCE_THRESHOLD: '0.30' # AI confidence threshold for article filtering
